{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-28T00:18:35.079675Z",
     "start_time": "2024-11-28T00:13:25.483738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skylercain/code/cs-6640-artificial-neural-networks/.direnv/python-3.11/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 55ms/step - accuracy: 0.1869 - loss: 2.9329 - val_accuracy: 0.3529 - val_loss: 2.1675\n",
      "Epoch 2/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 58ms/step - accuracy: 0.4127 - loss: 1.9968 - val_accuracy: 0.4477 - val_loss: 1.8364\n",
      "Epoch 3/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 57ms/step - accuracy: 0.5342 - loss: 1.5462 - val_accuracy: 0.4940 - val_loss: 1.7300\n",
      "Epoch 4/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 59ms/step - accuracy: 0.6135 - loss: 1.2668 - val_accuracy: 0.5055 - val_loss: 1.7148\n",
      "Epoch 5/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 58ms/step - accuracy: 0.6805 - loss: 1.0565 - val_accuracy: 0.5293 - val_loss: 1.7168\n",
      "Epoch 6/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 60ms/step - accuracy: 0.7321 - loss: 0.8824 - val_accuracy: 0.5281 - val_loss: 1.7865\n",
      "Epoch 7/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 59ms/step - accuracy: 0.7686 - loss: 0.7538 - val_accuracy: 0.5245 - val_loss: 1.8913\n",
      "Epoch 8/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 59ms/step - accuracy: 0.8076 - loss: 0.6447 - val_accuracy: 0.4957 - val_loss: 2.0688\n",
      "Epoch 9/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 59ms/step - accuracy: 0.8240 - loss: 0.5613 - val_accuracy: 0.5310 - val_loss: 2.1867\n",
      "Epoch 10/10\n",
      "\u001B[1m521/521\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 59ms/step - accuracy: 0.8475 - loss: 0.4926 - val_accuracy: 0.5257 - val_loss: 2.4852\n",
      "\u001B[1m321/321\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 16ms/step - accuracy: 0.5231 - loss: 2.4471\n",
      "Test Accuracy: 0.5306897759437561\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"data/kjvdata.csv\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "author_list = {\n",
    "    \"Genesis\": \"Moses\",\n",
    "    \"Exodus\": \"Moses\",\n",
    "    \"Leviticus\": \"Moses\",\n",
    "    \"Numbers\": \"Moses\",\n",
    "    \"Deuteronomy\": \"Moses\",\n",
    "    \"Joshua\": \"Joshua\",\n",
    "    \"Judges\": \"Samuel, Nathan, Gad\",\n",
    "    \"Ruth\": \"Samuel, Nathan, Gad\",\n",
    "    \"1 Samuel (1 Kings)\": \"Samuel, Nathan, Gad\",\n",
    "    \"2 Samuel (2 Kings)\": \"Samuel, Nathan, Gad\",\n",
    "    \"1 Kings (3 Kings)\": \"Jeremiah\",\n",
    "    \"2 Kings (4 Kings)\": \"Jeremiah\",\n",
    "    \"1 Chronicles\": \"Ezra\",\n",
    "    \"2 Chronicles\": \"Ezra\",\n",
    "    \"Ezra\": \"Ezra\",\n",
    "    \"Nehemiah\": \"Nehemiah, Ezra\",\n",
    "    \"Esther\": \"Mordecai\",\n",
    "    \"Job\": \"Job,Moses\",\n",
    "    \"Psalms\": \"David,Asaph, Ezra, the sons of Korah, Heman, Ethan, Moses\",\n",
    "    \"Proverbs\": \"Solomon ,Agur(30) and Lemuel(31)\",\n",
    "    \"Ecclesiastes\": \"Solomon\",\n",
    "    \"Song of Solomon (Canticles)\": \"Solomon\",\n",
    "    \"Isaiah\": \"Isaiah\",\n",
    "    \"Jeremiah\": \"Jeremiah\",\n",
    "    \"Lamentations\": \"Jeremiah\",\n",
    "    \"Ezekiel\": \"Ezekiel\",\n",
    "    \"Daniel\": \"Daniel\",\n",
    "    \"Hosea\": \"Hosea\",\n",
    "    \"Joel\": \"Joel\",\n",
    "    \"Amos\": \"Amos\",\n",
    "    \"Obadiah\": \"Obadiah\",\n",
    "    \"Jonah\": \"Jonah\",\n",
    "    \"Micah\": \"Micah\",\n",
    "    \"Nahum\": \"Nahum\",\n",
    "    \"Habakkuk\": \"Habakkuk\",\n",
    "    \"Zephaniah\": \"Zephaniah\",\n",
    "    \"Haggai\": \"Haggai\",\n",
    "    \"Zechariah\": \" Zechariah\",\n",
    "    \"Malachi\": \"Malachi\",\n",
    "    \"Matthew\": \"Matthew\",\n",
    "    \"Mark\": \"John Mark\",\n",
    "    \"Luke\": \"Luke\",\n",
    "    \"John\": \"John, the Apostle\",\n",
    "    \"Acts\": \"Luke\",\n",
    "    \"Romans\": \"Paul\",\n",
    "    \"1 Corinthians\": \"Paul\",\n",
    "    \"2 Corinthians\": \"Paul\",\n",
    "    \"Galatians\": \"Paul\",\n",
    "    \"Ephesians\": \"Paul\",\n",
    "    \"Philippians\": \"Paul\",\n",
    "    \"Colossians\": \"Paul\",\n",
    "    \"1 Thessalonians\": \"Paul\",\n",
    "    \"2 Thessalonians\": \"Paul\",\n",
    "    \"1 Timothy\": \"Paul\",\n",
    "    \"2 Timothy\": \"Paul\",\n",
    "    \"Titus\": \"Paul\",\n",
    "    \"Philemon\": \"Paul\",\n",
    "    \"Hebrews\": \"Paul, Luke, Barnabas, Apollos\",\n",
    "    \"James\": \"James the brother of Jesus and Jude (not the Apostle, brother of John).\",\n",
    "    \"1 Peter\": \"Peter\",\n",
    "    \"2 Peter\": \"Peter\",\n",
    "    \"1 John\": \"John, the Apostle\",\n",
    "    \"2 John\": \"John, the Apostle\",\n",
    "    \"3 John\": \"John, the Apostle\",\n",
    "    \"Jude\": \"Jude, the brother of Jesus\",\n",
    "    \"Revelation\": \"John, the Apostle\"\n",
    "}\n",
    "\n",
    "df['author'] = df['book'].map(author_list)\n",
    "df['author'].head()\n",
    "\n",
    "x_features = df['text']\n",
    "y_labels = df['author']\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_features)\n",
    "sequences = tokenizer.texts_to_sequences(x_features)\n",
    "\n",
    "# Padding sequences\n",
    "max_sequence_length = 100  # Adjust based on your dataset\n",
    "x_padded = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Splitting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_padded, y_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# Encoding labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y_train_enc = encoder.fit_transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_sequence_length),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(encoder.classes_), activation='softmax')  # Output size matches number of authors\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_enc, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test_enc)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff1d6a804b0cc12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
